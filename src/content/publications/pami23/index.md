---
title: "MILO: Multi-bounce inverse rendering for indoor scene with light-emitting objects"
summary: "Accepted to TPAMI 2023"
date: "Feb 13 2023"
draft: false
tags:
  - TPAMI
  - Inverse rendering
---

<div class="authors text-lg opacity-75 mb-6">
Bohan Yu, Siqi Yang, Xuanning Cui, Siyan Dong, Baoquan Chen, Boxin Shi
</div>

<div class="publication-source mb-8">
<div class="text-sm uppercase tracking-wide opacity-60 mb-2">Published in</div>
<div>IEEE Transactions on Pattern Analysis and Machine Intelligence</div>
</div>

<div class="abstract">
<div class="text-sm uppercase tracking-wide opacity-60 mb-2">Abstract</div>
<div class="text-justify">
Recently, many advances in inverse rendering are achieved by high-dimensional lighting representations and differentiable rendering. However, multi-bounce lighting effects can hardly be handled correctly in scene editing using high-dimensional lighting representations, and light source model deviation and ambiguities exist in differentiable rendering methods. These problems limit the applications of inverse rendering. In this paper, we present a multi-bounce inverse rendering method based on Monte Carlo path tracing, to enable correct complex multi-bounce lighting effects rendering in scene editing. We propose a novel light source model that is more suitable for light source editing in indoor scenes, and design a specific neural network with corresponding disambiguation constraints to alleviate ambiguities during the inverse rendering. We evaluate our method on both synthetic and real indoor scenes through virtual object insertion, material editing, relighting tasks, and so on. The results demonstrate that our method achieves better photo-realistic quality.
</div>
</div>
